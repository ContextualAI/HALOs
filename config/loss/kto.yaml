# Kahneman-Tversky Optimization
name: kto

# the temperature parameter for KTO; lower values mean we care less about the reference model
beta: 0.1

trainer: KTOTrainer

dataloader: UnpairedPreferenceDataLoader

use_reference_model: true

# how much to weigh the losses of desirable examples (when dataset is imbalanced)
desirable_weight: 1.0

# how much to weigh the losses of undesirable examples (when dataset is imbalanced)
undesirable_weight: 1.0

policy_hf_model_class: AutoModelForCausalLM

reference_hf_model_class: AutoModelForCausalLM

# whether KL estimate should be a running estimate that is KL_decay * previous_batch_estimate + (1 - KL_decay) * current_batch_estimate
# helpful when per-step batch size is small and gradient accumulation is needed
KL_decay: 0